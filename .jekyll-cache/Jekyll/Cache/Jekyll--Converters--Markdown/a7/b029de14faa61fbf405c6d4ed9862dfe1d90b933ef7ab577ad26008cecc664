I"~<p>Common classification problems in Machine Learning (ML) are binary and multi-class (Sokolova and Lapalme, 2009). For binary classification, we have <em>accuracy</em>, <em>precision</em>, <em>recall</em>, and a combination of <em>precision</em> and <em>recall</em> which is so-called \(F_1\) score. However, the <em>precision</em> and <em>recall</em> from binary classification cannot be utilized literally to measure multi-class classification.</p>

<p>To measure the performance of multi-class classification, two important modifications on precision and recall of binary classification are introduced. Their names are <strong>macro-average</strong> and <strong>micro-average</strong>. Therefore, for example, the precision of multi-class classification shall become <strong>macro-average</strong> precision and <strong>micro-average</strong> precision.</p>

<p>Let’s begin with an example of multi-class classification with \(4\) classes (\(0\), \(1\), \(2\), and \(3\)). Suppose we have \(\text{our predictions}\) and the \(\text{true labels}\) for five data instances as follows:</p>

\[\begin{align} 
        \text{our predictions} &amp;= [ 0, 0, 2, 2, 3 ],  \\
        \text{true labels} &amp;= [ 0, 1, 3, 3, 3 ] 
    \end{align}\]

<p>Our first prediction is $0$ and the true label is $0$. Next, our second prediction is $0$ and the true label is $1$. Our third prediction is $2$ while the true label is $3$ and so on. Let’s denote</p>

\[\begin{align} tp_i &amp;= \text{true positive for class }i \; (i = 0,1,2,3), \\
                fp_i &amp;= \text{false positive for class }i \; (i = 0,1,2,3).  \end{align}\]

<p>After counting the true and false positives for each class, we obtain</p>

\[\begin{align} tp_0 &amp;= 1, \; tp_1 = 0, \; tp_2 = 0, \; tp_3 = 1, \text{ and} \\
                fp_0 &amp;= 1, \; fp_1 = 0, \; fp_2 = 2, \; fp_3 = 0.  \end{align}\]

<p>As we’ve already known, $\text{precision}$ for class $i$ ($\text{precision}_i$) is defined as follows:</p>

\[\begin{equation}
    \text{precision}_i = \frac{tp_i}{tp_i + fp_i}, \text{ for }i = 0,1,2,3. \tag{1}\label{eq:precision-formula}
\end{equation}\]

<p>Therefore, employing Equation \eqref{eq:precision-formula}, we get</p>

\[\begin{equation}
    \text{precision}_0 = 0.5, \; \text{precision}_1 = 0, \; \text{precision}_2 = 0, \; \text{precision}_3 = 1. \tag{2}\label{eq:precision-results}
\end{equation}\]

<p>As explained in “<a href="https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin">Micro Average vs Macro average Performance in a Multiclass classification setting</a>”, the <strong>macro-average</strong> precision ($\text{precision}_M$) for $4$ classes is defined as</p>

\[\begin{align}
    \text{precision}_M &amp;= \frac{\sum_{i=0}^{3}{\text{precision}_i}}{4} \\
                       &amp;= \frac{0.5 + 0 + 0 + 1}{4} \\
                       &amp;= 0.375.
\end{align}\]

<p>However, the <strong>micro-average</strong> precision ($\text{precision}_\mu$) for $4$ classes is defined as</p>

\[\begin{align}
    \text{precision}_\mu &amp;= \frac{\sum_{i=0}^{3}{tp_i}}{\sum_{i=0}^{3}{(tp_i + fp_i)}} \\
                       &amp;= \frac{1+0+0+1}{2+0+2+1} \\
                       &amp;= 0.4.
\end{align}\]

<p>If there is a <a href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/">class imbalance problem</a>, one of the options will be using <strong>weighted macro-average</strong> as performance metrics. The <strong>weighted macro-average</strong> precision ($\text{precision}_{WM}$) for $4$ classes is defined as</p>

\[\begin{equation}
    \text{precision}_{WM} = \sum_{i=0}^{3} \text{weight}_i \times \text{precision}_i  \tag{3}\label{eq:weighted-precision}
\end{equation}\]

<p>with $\text{weight}_i$ is the weight assigned to class $i$ as follows:</p>

\[\begin{equation}
    \text{weight}_i = \frac{tp_i + fp_i}{\sum_{i=0}^{3}{(tp_i + fp_i)}} \tag{4}\label{eq:weight}
\end{equation}\]

<p>Using Equation \eqref{eq:weighted-precision} and \eqref{eq:weight}, we compute the <strong>weighted macro-average</strong> precision as follows:</p>

\[\begin{align}
    \text{precision}_{WM} &amp;= \frac{2}{5} \times 0.5 + 0 \times 0 + \frac{2}{5} \times 0 + \frac{1}{5} \times 1 \\
                          &amp;= 0.4.
\end{align}\]

<p>Next, we shall show that the <strong>weighted macro-average</strong> precision equals to the <strong>micro-average</strong> precision.</p>

\[\require{cancel} \begin{align}
    \text{precision}_{WM} &amp;= \sum_{i=0}^{3} \text{weight}_i \times \text{precision}_i   \\
                          &amp;= \sum_{i=0}^{3} \frac{tp_i + fp_i}{\sum_{i=0}^{3}{(tp_i + fp_i)}} \times \frac{tp_i}{tp_i + fp_i} \\
                          &amp;= \sum_{i=0}^{3} \frac{\cancel{tp_i + fp_i}}{\sum_{i=0}^{3}{(tp_i + fp_i)}} \times \frac{tp_i}{\cancel{tp_i + fp_i}} \\ 
                          &amp;= \sum_{i=0}^{3} {\frac{tp_i}{\sum_{i=0}^{3}{(tp_i + fp_i)}}} \\
                          &amp;= \frac{\sum_{i=0}^{3}{tp_i}}{\sum_{i=0}^{3}{(tp_i + fp_i)}} \\
                          &amp;= \text{precision}_\mu.

\end{align}\]

<p>Finally we have reached the end of this post. In brief, we have shown how to compute <strong>macro-average</strong>, <strong>micro-average</strong>, and <strong>weighted macro-average</strong>. Moreover, we have also shown that the <strong>micro-average</strong> equals to <strong>weighted macro-average</strong>.</p>

<p><br /></p>
<h4 id="references">References</h4>
<p>Sokolova, M. and Lapalme, G. (2009). A systematic analysis of performance measures for classification tasks. <em>Information Processing &amp; Management</em>, 45(4):427 - 437.</p>
:ET