I"Ì3<p>This article explains the implementation of <strong>Macro-averages</strong> and <strong>Weighted Macro-averages</strong> as explained in this <a href="https://hbunyamin.github.io/ml-2/Micro_and_Weighted_Macro_Averages">post</a> and this <a href="https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin">Data Science post</a>. Specifically, we add <strong>macro-averages</strong> and <strong>weighted macro-averages precision</strong> metrics into the <a href="https://course.fast.ai/videos/?lesson=3">lesson 3 of Practical Deep Learning for Coders, v3</a>.  <br />
Lesson 3 describes how to deal with <em>image segmentation</em> problem, that is predicting a category for each pixel in an image. The image dataset comes from <a href="https://course.fast.ai/datasets">CamVid dataset</a>.</p>

<p>In order to run the codes below, you need to install the <a href="https://github.com/fastai/fastai"><strong>fastai library</strong></a>.    <br />
Letâ€™s start by importing all the required libraries.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">reload_ext</span> <span class="n">autoreload</span>
<span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="kn">from</span> <span class="nn">fastai.vision</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.callbacks.hooks</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai.utils.mem</span> <span class="kn">import</span> <span class="o">*</span>
</code></pre></div></div>
<p>We <code class="highlighter-rouge">untar</code> the CamVid dataset.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">CAMVID</span><span class="p">)</span>
<span class="n">path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</code></pre></div></div>
<p>Out:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[PosixPath('/home/jupyter/.fastai/data/camvid/codes.txt'),
 PosixPath('/home/jupyter/.fastai/data/camvid/labels'),
 PosixPath('/home/jupyter/.fastai/data/camvid/valid.txt'),
 PosixPath('/home/jupyter/.fastai/data/camvid/images')]
</code></pre></div></div>

<p>We create a path to the <code class="highlighter-rouge">labels</code> and all <code class="highlighter-rouge">images</code>.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">path_lbl</span> <span class="o">=</span> <span class="n">path</span><span class="o">/</span><span class="s">'labels'</span>
<span class="n">path_img</span> <span class="o">=</span> <span class="n">path</span><span class="o">/</span><span class="s">'images'</span>
</code></pre></div></div>
<p>Letâ€™s get the images.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fnames</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path_img</span><span class="p">)</span>
<span class="n">fnames</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div></div>
<p>Out:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[PosixPath('/home/jupyter/.fastai/data/camvid/images/0001TP_008730.png'),
 PosixPath('/home/jupyter/.fastai/data/camvid/images/Seq05VD_f00090.png'),
 PosixPath('/home/jupyter/.fastai/data/camvid/images/0006R0_f03570.png')]
</code></pre></div></div>
<p>Letâ€™s show some image labels.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lbl_names</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path_lbl</span><span class="p">)</span>
<span class="n">lbl_names</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div></div>
<p>Out:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[PosixPath('/home/jupyter/.fastai/data/camvid/labels/0016E5_08067_P.png'),
 PosixPath('/home/jupyter/.fastai/data/camvid/labels/Seq05VD_f03870_P.png'),
 PosixPath('/home/jupyter/.fastai/data/camvid/labels/0016E5_01200_P.png')]
</code></pre></div></div>

<p>Letâ€™s show one image.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">img_f</span> <span class="o">=</span> <span class="n">fnames</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">open_image</span><span class="p">(</span><span class="n">img_f</span><span class="p">)</span>
<span class="n">img</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</code></pre></div></div>
<p>Out:
<a href="/assets/images/one-image.png"><img src="/assets/images/one-image.png" alt="img1" class="img-responsive" /></a></p>

<p>Next, we create a method to open a mask and show the mask.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">get_y_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">path_lbl</span><span class="o">/</span><span class="n">f</span><span class="s">'{x.stem}_P{x.suffix}'</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">open_mask</span><span class="p">(</span><span class="n">get_y_fn</span><span class="p">(</span><span class="n">img_f</span><span class="p">))</span>
<span class="n">mask</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>
<p>Out:
<a href="/assets/images/one-mask.png"><img src="/assets/images/one-mask.png" alt="img1" class="img-responsive" /></a></p>

<p>Letâ€™s view the mask data.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">src_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="n">src_size</span><span class="p">,</span><span class="n">mask</span><span class="o">.</span><span class="n">data</span>
</code></pre></div></div>
<p>Out:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([720, 960]),
 tensor([[[26, 26, 26,  ...,  4,  4,  4],
          [26, 26, 26,  ...,  4,  4,  4],
          [26, 26, 26,  ...,  4,  4,  4],
          ...,
          [17, 17, 17,  ..., 30, 30, 30],
          [17, 17, 17,  ..., 30, 30, 30],
          [17, 17, 17,  ..., 30, 30, 30]]]))
</code></pre></div></div>

<p>Particularly, the categories for each pixel are shown in code below.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">codes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s">'codes.txt'</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">);</span> <span class="n">codes</span>
</code></pre></div></div>
<p>Out:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array(['Animal', 'Archway', 'Bicyclist', 'Bridge', 'Building', 'Car', 'CartLuggagePram', 'Child', 'Column_Pole',
       'Fence', 'LaneMkgsDriv', 'LaneMkgsNonDriv', 'Misc_Text', 'MotorcycleScooter', 'OtherMoving', 'ParkingBlock',
       'Pedestrian', 'Road', 'RoadShoulder', 'Sidewalk', 'SignSymbol', 'Sky', 'SUVPickupTruck', 'TrafficCone',
       'TrafficLight', 'Train', 'Tree', 'Truck_Bus', 'Tunnel', 'VegetationMisc', 'Void', 'Wall'], dtype='&lt;U17')
</code></pre></div></div>

<p>Next, we use the appropriate batch size depending on the free GPU RAM.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">size</span> <span class="o">=</span> <span class="n">src_size</span><span class="o">//</span><span class="mi">2</span>

<span class="n">free</span> <span class="o">=</span> <span class="n">gpu_mem_get_free_no_cache</span><span class="p">()</span>
<span class="c1"># the max size of bs depends on the available GPU RAM
</span><span class="k">if</span> <span class="n">free</span> <span class="o">&gt;</span> <span class="mi">8200</span><span class="p">:</span> <span class="n">bs</span><span class="o">=</span><span class="mi">8</span>
<span class="k">else</span><span class="p">:</span>           <span class="n">bs</span><span class="o">=</span><span class="mi">4</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"using bs={bs}, have {free}MB of GPU RAM free"</span><span class="p">)</span>
</code></pre></div></div>
<p>Out:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>using bs=8, have 15068MB of GPU RAM free
</code></pre></div></div>
<p>Letâ€™s create our <code class="highlighter-rouge">data</code> with the reduced size (<code class="highlighter-rouge">src_size//2</code>) images and <code class="highlighter-rouge">get_transforms()</code> transformations. Please check the default <code class="highlighter-rouge">get_transforms()</code> transformation in <a href="https://docs.fast.ai/vision.transform.html">this documentation</a>.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">src</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">get_transforms</span><span class="p">(),</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">tfm_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="o">.</span><span class="n">databunch</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">)</span>
        <span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">imagenet_stats</span><span class="p">))</span>
</code></pre></div></div>

<p>We show several train images with both images and the labels.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
</code></pre></div></div>
<p>Out:
<a href="/assets/images/batch-train.png"><img src="/assets/images/batch-train.png" alt="img1" class="img-responsive" /></a></p>

<p>We show several validation images with both images and the labels.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="n">ds_type</span><span class="o">=</span><span class="n">DatasetType</span><span class="o">.</span><span class="n">Valid</span><span class="p">)</span>
</code></pre></div></div>
<p>Out:
<a href="/assets/images/batch-valid.png"><img src="/assets/images/batch-valid.png" alt="img1" class="img-responsive" /></a></p>

<p>There is <code class="highlighter-rouge">Void</code> category in CamVid dataset and this category</p>
:ET