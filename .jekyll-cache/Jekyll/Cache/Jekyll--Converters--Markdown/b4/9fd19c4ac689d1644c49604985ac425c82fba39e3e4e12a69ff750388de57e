I"›!<p>The subchapter 2.5 of <a href="http://www.stat.columbia.edu/~gelman/book/BDA3.pdf"><strong>Bayesian Data Analysis Third Edition</strong></a> explains how to estimate a normal mean with known variance; particularly, the subchapter extends the development of a normal model with a single observation into the more realistic situation where <em>a sample of independent and identically distributed observations</em> $y = (y_1, \ldots, y_n)$ are available.</p>

<p><a href="/assets/images/normal-dist.jpg"><img src="/assets/images/normal-dist.jpg" alt="img1" class="img-responsive" /></a><em><center>$\pmb{\text{Figure 1}}$: Example of a normal distribution consisting a horde of rabbits. Image taken from <a href="https://vimeo.com/75089338">Casey Dunn</a>, some rights reserved.</center></em></p>

<p>The <em>posterior</em> density of the normal model consists of a <em>likelihood</em> distribution, $\Pr(y \mid \theta)$, and a <em>prior</em> distribution, $\Pr(\theta)$. Proceeding formally, the posterior density is</p>

\[\begin{align}
\Pr(\theta \mid y) &amp;\
\end{align}\]

<p>Concretely, we want to show the derivation $J(\theta)$, the <em>Fisher Information</em>, from</p>

\[\begin{equation}
	J(\theta) = \text{E}\left( \left( \frac{d \log \Pr(y \mid \theta )}{d\theta} \right)^2 \, \middle| \, \theta \right) \tag{1}\label{eq:start-point}
\end{equation}\]

<p>to</p>

\[\begin{equation}
	J(\theta) = - \text{E}\left( \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2} \, \middle| \, \theta \right). \tag{2}\label{eq:end-point}
\end{equation}\]

<p>The idea of this derivation comes from a <a href="https://web.stanford.edu/class/stats311/Lectures/lec-09.pdf"><strong>lecture note by John Duchi from Stanford Statistics class</strong></a>. The difference between this post and the lecture note is that the lecture note deals with <em>multi-variables</em> which employs second derivatives for multi-values (<a href="https://en.wikipedia.org/wiki/Hessian_matrix"><em>Hessian matrix</em></a>); on the other hand, this post deals with a single variable and employs a second derivative for just one value.</p>

<p>Letâ€™s start with computing 
\(\begin{equation} 
	\text{E} \left( \frac{d \log \Pr(y \mid \theta)}{d\theta} \, \middle| \, \theta \right)
\end{equation}\).</p>

\[\require{cancel} \begin{align}
	\text{E}\left( \frac{d \log \Pr(y \mid \theta)}{d\theta} \, \middle| \, \theta \right) &amp;= \int \frac{d \log \Pr(y \mid \theta)}{d\theta} \Pr(y \mid \theta) d\theta  &amp;&amp; \text{definition of expectation} \tag{3}\label{eq:dlog-1} \\
	&amp;= \int \frac{d \Pr(y \mid \theta)}{d\theta} \frac{1}{\Pr(y \mid \theta)} \; \Pr(y \mid \theta) d\theta  &amp;&amp; \text{derivation of }\frac{d \log \Pr(y \mid \theta)}{d\theta} \tag{4}\label{eq:dlog-2} \\
	&amp;= \int \frac{d \Pr(y \mid \theta)}{d\theta} \frac{1}{\cancel{\Pr(y \mid \theta)}} \; \cancel{\Pr(y \mid \theta)}  d\theta \tag{5}\label{eq:dlog-3}	 \\
	&amp;= \int \frac{d \Pr(y \mid \theta)}{d\theta} d\theta  \tag{6}\label{eq:dlog-4}	 \\
	&amp;= \frac{d}{d\theta} \int \Pr(y \mid \theta) d\theta &amp;&amp; \text{exchange }\frac{d}{d\theta} \text{ and } \int \tag{7}\label{eq:dlog-5} \\
	&amp;= \frac{d}{d\theta} \underbrace{\int \Pr(y \mid \theta) d\theta}_{1} &amp;&amp; \text{property of a pdf}\tag{8}\label{eq:dlog-6} \\
	&amp;= \frac{d}{d\theta} (1) \tag{9}\label{eq:dlog-7} 	\\
	&amp;= 0. \tag{10}\label{eq:dlog-8}
\end{align}\]

<p>Consider Equation \eqref{eq:dlog-5}, we shall utilize this exchangeability between <em>integral</em> and <em>differentiation</em> again later.</p>

<p>Equation \eqref{eq:dlog-2} states that</p>

\[\begin{equation}
	\frac{d \log \Pr(y \mid \theta)}{d\theta} = \underbrace{\frac{1}{\Pr(y \mid \theta)}}_{u}  \underbrace{\frac{d \Pr(y \mid \theta)}{d\theta}}_{v}. \tag{11}\label{eq:first-order-derivation}
\end{equation}\]

<p>Therefore,</p>

\[\begin{align}
	\frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2} &amp;= \underbrace{- \frac{1}{\Pr( y \mid \theta )^2} \frac{d \Pr(y \mid \theta)}{d\theta}}_{u^{\prime}} \underbrace{\frac{d \Pr(y \mid \theta)}{d\theta}}_{v}  + \underbrace{\frac{1}{\Pr(y \mid \theta)}}_{u} \underbrace{\frac{d^2 \Pr(y \mid \theta)}{d\theta^2}}_{v^{\prime}} &amp;&amp;  \text{based on } u^{\prime} v + u v^{\prime} \tag{12}\label{eq:second-order-1} \\
	&amp;= \frac{d^2 \Pr(y \mid \theta)}{d\theta^2} \frac{1}{\Pr(y \mid \theta)} - \left( \frac{d\Pr(y \mid \theta)}{d\theta} \frac{1}{\Pr(y \mid \theta)}  \right) \left( \frac{d\Pr(y \mid \theta)}{d\theta} \frac{1}{\Pr(y \mid \theta)}  \right) &amp;&amp; \text{just rearranging} \tag{13}\label{eq:second-order-2} \\
	&amp;= \frac{d^2 \Pr(y \mid \theta)}{d\theta^2} \frac{1}{\Pr(y \mid \theta)} - \left(  \frac{d \log \Pr( y \mid \theta)}{d\theta} \right) \left( \frac{d \log \Pr( y \mid \theta)}{d\theta} \right) &amp;&amp; \text{based on Equation }\eqref{eq:first-order-derivation} \tag{14}\label{eq:second-order-3} \\	
	&amp;= \frac{d^2 \Pr(y \mid \theta)}{d\theta^2} \frac{1}{\Pr(y \mid \theta)} - \left(  \frac{d \log \Pr( y \mid \theta)}{d\theta} \right)^{2} \tag{15}\label{eq:second-order-4}		
\end{align}\]

<p>From Equation \eqref{eq:second-order-4} we obtain</p>

\[\begin{align}
	\frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2} = \frac{d^2 \Pr(y \mid \theta)}{d\theta^2} \frac{1}{\Pr(y \mid \theta)} - \left(  \frac{d \log \Pr( y \mid \theta)}{d\theta} \right)^{2} &amp;\Longleftrightarrow \left(  \frac{d \log \Pr( y \mid \theta)}{d\theta} \right)^{2} = - \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2} + \frac{d^2 \Pr(y \mid \theta)}{d\theta^2} \frac{1}{\Pr(y \mid \theta)} \tag{16}\label{eq:second-order-last}
\end{align}\]

<p>Now we are ready to calculate
\(\begin{equation}
	\text{E}\left( \left( \frac{d \log \Pr(y \mid \theta )}{d\theta} \right)^2 \, \middle| \, \theta \right).
\end{equation}\)</p>

\[\require{cancel} \begin{align}
	\text{E}\left( \left( \frac{d \log \Pr(y \mid \theta )}{d\theta} \right)^2 \, \middle| \, \theta \right) &amp;= \int \left( \frac{d \log \Pr(y \mid \theta )}{d\theta} \right)^2 \Pr(y \mid \theta) d\theta &amp;&amp; \text{by definition} \tag{17}\label{eq:final-showdown-1}\\
	&amp;= \int \left( - \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2} + \frac{d^2 \Pr(y \mid \theta)}{d\theta^2} \frac{1}{\Pr(y \mid \theta)} \right) \Pr(y \mid \theta) d\theta &amp;&amp; \text{by Equation }\eqref{eq:second-order-last} \tag{18}\label{eq:final-showdown-2}\\
	&amp;= \int \left( - \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2}  \right) \Pr(y \mid \theta) d\theta + \int \frac{d^2 \Pr(y \mid \theta)}{d\theta^2} \frac{1}{\Pr(y \mid \theta)} \Pr(y \mid \theta) d\theta &amp;&amp; \text{by distributive} \tag{19}\label{eq:final-showdown-3}\\
	&amp;= \int \left( - \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2}  \right) \Pr(y \mid \theta) d\theta + \int \frac{d^2 \Pr(y \mid \theta)}{d\theta^2} \frac{1}{\cancel{\Pr(y \mid \theta)}} \cancel{\Pr(y \mid \theta)} d\theta  \tag{20}\label{eq:final-showdown-4}\\		
	&amp;= \int \left( - \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2}  \right) \Pr(y \mid \theta) d\theta + \int \frac{d^2 \Pr(y \mid \theta)}{d\theta^2} d\theta  \tag{21}\label{eq:final-showdown-5}\\
	&amp;= \int \left( - \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2}  \right) \Pr(y \mid \theta) d\theta + \frac{d^2}{d\theta^2} \left( \int \Pr(y \mid \theta) d\theta \right) &amp;&amp; \text{by exchangeability again}  \tag{22}\label{eq:final-showdown-6}\\	
	&amp;= \int \left( - \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2}  \right) \Pr(y \mid \theta) d\theta + \underbrace{\frac{d^2}{d\theta^2} \left( \int \Pr(y \mid \theta) d\theta \right)}_{0} &amp;&amp; \text{similar to Equation }\eqref{eq:dlog-8}  \tag{23}\label{eq:final-showdown-7}\\					
	&amp;= \int \left( - \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2}  \right) \Pr(y \mid \theta) d\theta \tag{24}\label{eq:final-showdown-8}\\
	&amp;= - \int \left( \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2}  \right) \Pr(y \mid \theta) d\theta \tag{25}\label{eq:final-showdown-9}\\											
	&amp;= - \text{E}\left( \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2} \, \middle| \, \theta  \right). &amp;&amp; \text{by definition} \tag{26}\label{eq:final-showdown-10}					
\end{align}\]

<p>At last, we have finally shown that</p>

\[\begin{equation}
	J(\theta) = \text{E}\left( \left( \frac{d \log \Pr(y \mid \theta )}{d\theta} \right)^2 \, \middle| \, \theta \right)  = - \text{E}\left( \frac{d^2 \log \Pr(y \mid \theta)}{d\theta^2} \, \middle| \, \theta \right)
\end{equation}\]

<p>as it is explained by Equation (2.20) on page 53 of the <a href="http://www.stat.columbia.edu/~gelman/book/BDA3.pdf"><strong>book</strong></a>.</p>
:ET