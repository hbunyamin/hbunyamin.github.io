I"±<p>Common classification problems in Machine Learning (ML) are binary and multi-class (Sokolova and Lapalme, 2009). For binary classification, we have <em>accuracy</em>, <em>precision</em>, <em>recall</em>, and a combination of <em>precision</em> and <em>recall</em> which is so-called <script type="math/tex">F_1</script> score. However, the <em>precision</em> and <em>recall</em> from binary classification cannot be utilized literally to measure multi-class classification.</p>

<p>To measure the performance of multi-class classification, two important modifications on precision and recall of binary classification are introduced. Their names are <strong>macro-average</strong> and <strong>micro-average</strong>. Therefore, for example, the precision of multi-class classification shall be <strong>macro-average</strong> precision and <strong>micro-average</strong> precision.</p>

<p>Let‚Äôs begin with an example of multi-class classification with <script type="math/tex">4</script> classes (<script type="math/tex">0</script>, <script type="math/tex">1</script>, <script type="math/tex">2</script>, and <script type="math/tex">3</script>). Suppose we have <script type="math/tex">\text{our predictions}</script> and the <script type="math/tex">\text{true labels}</script> for five data instances as follows:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} 
        \text{our predictions} &= [ 0, 0, 2, 2, 3 ],  \\
        \text{true labels} &= [ 0, 1, 3, 3, 3 ] 
    \end{align} %]]></script>

<p>Our first prediction is $0$ and the true label is $0$. Next, our second prediction is $0$ and the true label is $1$. Our third prediction is $2$ while the true label is $3$ and so on. Let‚Äôs denote</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} tp_i &= \text{true positive for class }i \; (i = 0,1,2,3), \\
                fp_i &= \text{false positive for class }i \; (i = 0,1,2,3).  \end{align} %]]></script>

<p>After counting the true and false positives for each class, we obtain</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} tp_0 &= 1, \; tp_1 = 0, \; tp_2 = 0, \; tp_3 = 1, \text{ and} \\
                fp_0 &= 1, \; fp_1 = 0, \; fp_2 = 2, \; fp_3 = 0.  \end{align} %]]></script>

<p>As we‚Äôve already known, $\text{precision}$ for class $i$ ($\text{precision}_i$) is defined as follows:</p>

<script type="math/tex; mode=display">\begin{equation}
    \text{precision}_i = \frac{tp_i}{tp_i + fp_i}, \text{ for }i = 0,1,2,3.
\end{equation}</script>

<p>As explained in ‚Äú<a href="https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin">Micro Average vs Macro average Performance in a Multiclass classification setting</a>‚Äù, the <strong>macro-average</strong> precision ($\text{precision}_M$) for $4$ classes is defined as</p>

<script type="math/tex; mode=display">\begin{equation}
    \text{precision}_M = \frac{\sum_{l=0}}{}
\end{equation}</script>

<p><br /></p>
<h4 id="references">References</h4>
<p>Sokolova, M. and Lapalme, G. (2009). A systematic analysis of performance measures for classification tasks. <em>Information Processing &amp; Management</em>, 45(4):427 - 437.</p>
:ET